1
00:00:00,766 --> 00:00:02,700
当v0出来的时候

2
00:00:02,800 --> 00:00:07,200
使用它一键生成网络程序和应用

3
00:00:07,200 --> 00:00:08,866
相当的高效率

4
00:00:08,866 --> 00:00:10,300
效果相当的好

5
00:00:10,366 --> 00:00:15,100
有没有本地免费部署的同类的平台呢

6
00:00:15,766 --> 00:00:19,400
是有的。之后出了一个Bolt.new

7
00:00:19,700 --> 00:00:23,166
全栈web应用开发平台

8
00:00:23,433 --> 00:00:28,866
它是可以本地免费部署

9
00:00:28,866 --> 00:00:32,900
但是它只支持Claude3.5的API

10
00:00:32,900 --> 00:00:34,100
相当昂贵

11
00:00:34,700 --> 00:00:39,433
直到这位老哥出的这一个开源的Bolt(支持其它API)

12
00:00:40,266 --> 00:00:43,300
看一下他比原版多了什么功能

13
00:00:43,433 --> 00:00:47,266
他支持Openrouter的API

14
00:00:47,766 --> 00:00:50,466
集成了Gemini的API

15
00:00:51,100 --> 00:00:55,433
还有欧拉玛的API也可以使用

16
00:00:56,500 --> 00:00:57,300
还有

17
00:00:58,800 --> 00:01:00,600
还有其他的一些功能

18
00:01:00,700 --> 00:01:04,066
比如下载项目文件代码

19
00:01:04,766 --> 00:01:09,100
然后呢还有 DeepSeek、Mistral的API

20
00:01:09,633 --> 00:01:14,166
还有openAI兼容的API都可以使用

21
00:01:15,800 --> 00:01:17,666
还能支持Docker部署

22
00:01:18,400 --> 00:01:23,100
还支持将项目文件同步到Github上

23
00:01:29,300 --> 00:01:34,833
我们现在在Windows本地部署这个Bolt

24
00:01:34,900 --> 00:01:37,800
我们首先要确认安装了pnpm

25
00:01:37,800 --> 00:01:40,233
看一下pnpm版本

26
00:01:40,366 --> 00:01:41,566
没有安装的话

27
00:01:41,566 --> 00:01:46,100
我视频下方提供的链接中

28
00:01:46,100 --> 00:01:49,466
有相关的安装步骤和安装代码

29
00:01:50,600 --> 00:01:57,966
好了然后我们要将项目复制进来

30
00:02:00,433 --> 00:02:03,066
复制这一句命令运行之后

31
00:02:03,066 --> 00:02:07,100
他就克隆仓库代码进来

32
00:02:10,433 --> 00:02:13,366
首次克隆失败

33
00:02:13,366 --> 00:02:15,566
因为我们的网络不通畅

34
00:02:16,200 --> 00:02:18,800
一般使用这一个软件（watt Toolkit）就可以了

35
00:02:18,800 --> 00:02:21,400
我们再试试一下

36
00:02:22,900 --> 00:02:25,433
好了已经克隆完成了

37
00:02:25,433 --> 00:02:27,866
我们进入根目录

38
00:02:32,033 --> 00:02:33,166
来到根目录

39
00:02:33,166 --> 00:02:34,500
来到根目录

40
00:02:37,766 --> 00:02:38,600
来到根目录

41
00:02:38,600 --> 00:02:43,900
我们使用第一个命令进行依赖的安装

42
00:02:48,600 --> 00:02:50,100
这个安装也挺快的

43
00:02:50,100 --> 00:02:54,400
因为我设置了pnpm的源为腾讯的

44
00:02:54,400 --> 00:02:56,800
源还是国内的比较快

45
00:02:57,633 --> 00:03:01,466
然后我们修改一下API的设置文件（.env.local）

46
00:03:03,766 --> 00:03:05,000
之后呢我们

47
00:03:06,400 --> 00:03:08,700
还是新建一个窗口 (cursor .)

48
00:03:09,033 --> 00:03:10,400
打开这个项目

49
00:03:14,300 --> 00:03:17,100
我们来看一下API的设置文件(.env.local)

50
00:03:19,166 --> 00:03:22,266
这里可以看到可以设置Groq的API

51
00:03:22,500 --> 00:03:23,766
openai的API

52
00:03:25,200 --> 00:03:26,166
Claude家的API

53
00:03:26,166 --> 00:03:29,300
还有openrouter的API

54
00:03:29,400 --> 00:03:30,800
谷歌家的API

55
00:03:32,000 --> 00:03:34,066
还有DeepSeek的API

56
00:03:36,200 --> 00:03:39,433
兼容openAI的API

57
00:03:40,066 --> 00:03:41,700
还有Mistral的API

58
00:03:42,433 --> 00:03:46,500
我们先是使用Mistral的API进行测试

59
00:03:46,900 --> 00:03:48,566
Mistral的API

60
00:03:48,566 --> 00:03:54,000
大家可以直接按它的官网进行注册

61
00:03:54,000 --> 00:03:56,566
登录、创建API来使用

62
00:03:56,800 --> 00:04:00,300
国内都可以注册和登录的

63
00:04:00,300 --> 00:04:02,766
好了我们运行这一个命令

64
00:04:04,233 --> 00:04:07,666
打开程序来进行测试

65
00:04:10,200 --> 00:04:11,233
稍微等一下

66
00:04:11,233 --> 00:04:15,433
他就会提供本地运行的一个网址

67
00:04:15,566 --> 00:04:19,266
打开之后来到项目的主页

68
00:04:20,166 --> 00:04:22,266
看到熟悉的页面了吧

69
00:04:22,300 --> 00:04:26,966
这里我们看到众多API可以选择

70
00:04:26,966 --> 00:04:28,833
我们选择Mistral的API

71
00:04:29,800 --> 00:04:33,000
选择最大最好的那个模型

72
00:04:33,166 --> 00:04:36,566
我们让他帮我们写一个扫雷游戏

73
00:04:36,566 --> 00:04:39,633
看到他已经开始创建文件

74
00:04:40,766 --> 00:04:42,866
还有运行相关的命令

75
00:04:42,900 --> 00:04:46,600
好了看到他生成程序完成

76
00:04:46,900 --> 00:04:50,200
自动帮我们打开游戏的预览页面

77
00:04:50,200 --> 00:04:51,600
我们来测试一下

78
00:04:54,033 --> 00:04:55,166
哦 踩中雷了

79
00:04:56,066 --> 00:04:58,233
但是踩中雷之后还能继续玩

80
00:04:59,400 --> 00:05:00,833
这是个bug

81
00:05:01,633 --> 00:05:04,600
然后让他再帮我们修改一下

82
00:05:10,233 --> 00:05:13,466
修改完成我们再来测一下

83
00:05:13,466 --> 00:05:16,800
游戏刷新之后测试一下

84
00:05:17,866 --> 00:05:21,033
然后中雷之后就不能再点再继续玩游戏了

85
00:05:21,100 --> 00:05:26,233
好现在我们来设置一下ollama的API

86
00:05:26,633 --> 00:05:28,900
网址一般都是这一个

87
00:05:29,700 --> 00:05:33,300
如果还没下载安装ollama的

88
00:05:33,300 --> 00:05:35,433
就到官网去下载一下

89
00:05:35,433 --> 00:05:37,666
我这里是Windows版本的

90
00:05:38,200 --> 00:05:39,700
下载安装就行了

91
00:05:40,366 --> 00:05:44,000
大语言模型的安装也是很简单的啊

92
00:05:44,000 --> 00:05:44,766
设置好之后

93
00:05:44,766 --> 00:05:49,833
我们再来进行一下Bolt的运行

94
00:05:50,633 --> 00:05:55,900
我们输入pnpm dev来运行一下

95
00:05:56,800 --> 00:05:58,800
打开项目网址

96
00:05:58,800 --> 00:06:01,266
选择ollama的API

97
00:06:01,566 --> 00:06:03,566
我这里本地只安装了

98
00:06:03,566 --> 00:06:06,266
qwen（千问）2.5的一个模型

99
00:06:06,466 --> 00:06:07,700
我来测试一下

100
00:06:07,700 --> 00:06:08,800
他出错了

101
00:06:09,233 --> 00:06:10,666
看一下什么原因

102
00:06:11,100 --> 00:06:13,600
他说缺少这一个(anthropic)API key

103
00:06:14,266 --> 00:06:17,166
所以我们随便输入一个key

104
00:06:17,433 --> 00:06:19,666
再来进行测试

105
00:06:19,966 --> 00:06:22,366
我们再次运行这一个程序

106
00:06:24,000 --> 00:06:26,633
这一次还是选择ollama的API

107
00:06:28,000 --> 00:06:30,700
好 我们来问一个问题

108
00:06:30,900 --> 00:06:37,000
让他帮我生成一个居中的div块

109
00:06:38,433 --> 00:06:40,833
好了，看到他成功了

110
00:06:40,833 --> 00:06:43,466
我们新建一个对话

111
00:06:43,700 --> 00:06:48,600
让他帮我写一个flask的示范程序

112
00:06:51,000 --> 00:06:55,166
之后他就正常的在运行（生成）

113
00:06:56,366 --> 00:06:57,900
但是有一个不正常的

114
00:06:57,900 --> 00:07:02,300
就是没有看到他自动生成相关的文件

115
00:07:04,066 --> 00:07:05,600
所以也不会Preview

116
00:07:06,000 --> 00:07:09,400
就说也不会预览生成的应用

117
00:07:09,400 --> 00:07:09,800
好了

118
00:07:09,800 --> 00:07:13,066
我们可以看右手边这里的下载代码

119
00:07:13,500 --> 00:07:14,700
还有同步文件

120
00:07:14,700 --> 00:07:16,366
还有发布到Github

121
00:07:16,600 --> 00:07:18,100
都是这一个

122
00:07:18,233 --> 00:07:21,666
开源项目比原项目多的功能

123
00:07:22,166 --> 00:07:24,100
增加的功能哦

124
00:07:24,800 --> 00:07:27,866
现在对本次部署进行总结

125
00:07:27,966 --> 00:07:29,633
首先这一个开源Bolt

126
00:07:29,633 --> 00:07:31,700
支持众多远程API

127
00:07:32,433 --> 00:07:37,233
我们使用了国内可以申请到的Mistral的API

128
00:07:37,233 --> 00:07:38,266
进行测试

129
00:07:38,600 --> 00:07:41,500
功能和预览等都正常

130
00:07:41,966 --> 00:07:45,066
我们下期视频要在Bolt中使用

131
00:07:45,066 --> 00:07:47,900
使用ChatGPT-4o的免费API

132
00:07:48,800 --> 00:07:49,900
请关注我!

133
00:07:50,633 --> 00:07:51,000
然后

134
00:07:51,000 --> 00:07:55,633
我们看到这个本地ollama的设置中

135
00:07:56,700 --> 00:07:59,566
除了设置好Base URL之外

136
00:08:00,033 --> 00:08:04,966
它还需要在这一个anthropic API key中进行设置

137
00:08:05,766 --> 00:08:07,500
随便输入内容就行

138
00:08:07,566 --> 00:08:09,866
不知道以后版本会不会改进

139
00:08:09,866 --> 00:08:12,666
现在最新版本就是要这样设置

140
00:08:12,666 --> 00:08:14,600
才能正常使用ollama

141
00:08:14,600 --> 00:08:18,066
但是呢我使用的是qwen（千问）2.5的模型

142
00:08:18,233 --> 00:08:20,766
它竟然并不支持生存预览

143
00:08:21,600 --> 00:08:24,400
估计可能是要支持工具调用

144
00:08:24,400 --> 00:08:26,766
的一些大语言模型

145
00:08:26,766 --> 00:08:28,400
才能成预览吧

146
00:08:28,666 --> 00:08:32,500
之后我将在ollama的更多模型中找出

147
00:08:32,500 --> 00:08:36,666
可以支持Bolt使用的一些大语言模型

148
00:08:36,900 --> 00:08:39,600
好了本期视频就到这里了

149
00:08:40,033 --> 00:08:42,233
如果觉得有帮助的话

150
00:08:42,233 --> 00:08:44,766
请给我个关注和点赞

151
00:08:44,766 --> 00:08:47,366
谢谢。我们下期视频再见

