## 本地免费部署deepseek R1模型快速拥有自己的RAG

本地使用deepseek R1模型+anythingLLM快速部署RAG，有手就行，完全免费，简单快速

亲测稳定好用梯子128元一年：https://flowercloud.net/aff.php?aff=7344

nsfw r1 模型: https://huggingface.co/collections/huihui-ai/deepseek-r1-abliterated-6790ea12ce8c8c4e5df51b7f

ollama 官网: https://ollama.com/
anythingLLM 官网: https://anythingllm.com/
超算中心：https://chat.scnet.cn/#/home

逆向API: https://www.bilibili.com/video/BV11i6nYgEgS/

交流群：
企微  https://qr61.cn/oohivs/qRp62U6
Discord https://discord.gg/3JWMgKQznF


大家新年好。给大家送上一个deepseek利器，利用DeepSeek加Anything LLM来快速打造你自己的RAG知识管理系统，人人都可以拥有，完全免费。你的返工必备，让我们开始吧。

本视频使用本地主机安装ollama来部署deepseek R1相关模型。
之后我们就能使用anything LLM 来快速实现我们的知识库及知识管理系统。
为什么选择anything LLM呢?
它支持PDF/TXT/DOCX/CSV等众多格式解析，集成向量化引擎，自动同步GitHub等数据源进行动态知识更新，保密性好，特别适合需要高精度、强时效、严合规等场景中使用。
现在，我们只需要点击这里，看到支持三大桌面平台，下载相应的 anything LLM的桌面软件，安装后打开。

大家使用默认设置进入到anythingLLM中，我们点击左下角的扳手标志进行软件的设置。
进入人工智能供应商下的LLM首选项中，我们选择先选择供应商，我们有四种方式在anything LLM中使用deepseek，第一就是deepseek的官方api，但因为某些原因，现在申请不了API，过一段时间应该就会恢复的，推荐这种方式。第二种是我往期视频中分享过的逆向API获取到的免费API，可能不太稳定，有兴趣可以看我往期视频，视频链接放在视频下方。第三种就是本地安装ollama，如果显卡不好或没有显卡，还有第四种方法最适合不过了。
本视频使用第三种方法来实现，首先需要在本地安装ollama，在官网这里直接下载安装就行。本视频以windows主机为例，在ollama中下载deepseek模型。安装并运行ollama后，我们打开命令提示符，也就是CMD终端，使用命令 ollama run deepseek-r1:7b就自动下载并运行模型。我们来测试一下，随便问一个问题，看到回答速度不错，输入斜杆加bye来退出对话。在浏览器中打开 127.0.0.1:11434，会看到“Ollama is running”。
在anythingLLM中，ollama的base url填入127.0.0.1:11434。正确输入后，ollama model中就能选择ollama已经下载的模型。我们选择14B模型来使用。我们点击左下角的返回标志返回到对话界面中，
我们测一下连接正确否，随便问它一个问题。看到了正确的回答，你个人的RAG就搭建成功了。

要使用rag还需要下载embedding模型，推荐[bge-m3](https://ollama.com/library/bge-m3)和[nomic](https://ollama.com/library/nomic-embed-text)，我们来到 bge-m3的页面中，使用这一行命令来下载模型，复制后来到CMD终端中粘贴来下载模型。
之后，我们点击这个扳手图标，来到anythingLLM设置中，来到embedder选项中，选择ollama，选择刚才下载好的bge-m3模型。全部设置完成了。
要如何使用RAG呢，比如这个视频的总结内容，我这里点击左下角的附件按钮，上传视频的字幕文件，并让deepseek给我们总结，很快就得到视频总结的内容了。
整个部署及使用教程就完成了，

最后，我还来说说如何不受限制的使用LLM，很简单，只需要使用这一个模型，我们还是以14B为例，点击进来后，使用最后面的那一行命令来下载模型就行了。
好了，祝大家开工大吉，你们的点赞关注正好是我需要的，谢谢。
补充一下两条关于deepseek的资讯，官网今天恢复了联网搜索。超算互联网上也可以用deepseek 蒸馏的模型了，现在有7，14，32B三个模型可用。
我们下期视频再见。

